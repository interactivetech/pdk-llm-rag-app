apiVersion: v1
kind: Pod
metadata:
  name: titanml-pod
  labels:
    name: titanml-pod
spec:
  containers:
  - name: ubuntu
    image: mendeza/takeoff-mistral:0.5
    command: ["/bin/sh", "-c"]
    args:
      - echo starting;
        export TAKEOFF_MODEL_NAME={{TAKEOFF_MODEL_NAME}};
        export TAKEOFF_DEVICE={{TAKEOFF_DEVICE}};
        export API_PORT={{API_PORT}};
        sh run.sh
    ports:
    - containerPort: {{API_PORT}}
      hostPort: {{API_PORT}}
    volumeMounts:
    - name: titanml-cache
      mountPath: /code/models/
    - name: host-volume
      mountPath: /nvmefs1/
    resources:
      limits:
        nvidia.com/gpu: 1 #specify number of gpus required
  tolerations:
    - effect: NoSchedule
      key: accelerator
      operator: Equal
      value: {{GPU_DEVICE}}
  volumes:
  - name: titanml-cache
    hostPath:
      path: {{LOCAL_TITANML_CACHE}}
  - name: host-volume
    hostPath:
      path: {{LOCAL_VOLUME}}
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app: titanml-pod-svc
  name: titanml-pod-svc
spec:
  type: LoadBalancer
  ports:
  - nodePort: 31174
    port: {{API_PORT}}
    protocol: TCP
    targetPort: {{API_PORT}}
  selector:
    name: titanml-pod
  sessionAffinity: None
  type: LoadBalancer
  loadBalancerIP: {{API_HOST}}
