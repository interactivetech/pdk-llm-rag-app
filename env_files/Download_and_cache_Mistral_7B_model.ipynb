{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "655441ca-4e52-4556-8dc3-6dad95d75fd3",
   "metadata": {},
   "source": [
    "# Download and Cache Mistral 7B model\n",
    "CACHE_DIR is set to /nvmefs1/test_user/cache/, make sure to change this to the directory of choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a8acc44-0ffd-43ef-b21d-051a02deacf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformers version: 4.36.0.dev0\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "import importlib\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "\n",
    "print(f\"Transformers version: {transformers.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37433d0f-d66c-42ad-a972-29d827054224",
   "metadata": {},
   "source": [
    "## Restart kernel to ensure transformimport transformersers 4.36 is loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f43d3a2-0e00-4a3e-9531-3d913824ff06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformers version: 4.36.0.dev0\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "import torch\n",
    "import os\n",
    "print(f\"Transformers version: {transformers.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "650b48cd-6f17-4ccc-84c7-c3f7e02d8f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/nvmefs1/test_user/cache/model_cache/mistral_7b_model_tokenizer\n",
      "/nvmefs1/test_user/cache/model_cache/mistral_7b_model_tokenizer\n"
     ]
    }
   ],
   "source": [
    "CACHE_DIR='/nvmefs1/test_user/cache/'\n",
    "model_cache_dir=os.path.join(CACHE_DIR,'model_cache/mistral_7b_model_tokenizer')\n",
    "print(model_cache_dir)\n",
    "tokenizer_cache_dir=os.path.join(CACHE_DIR,'model_cache/mistral_7b_model_tokenizer')\n",
    "print(tokenizer_cache_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53c46893-70a9-4883-a82b-3b1590bfedb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62e4a4c0fcea42d7aeb7c5e5ddd932a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/1.47k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "973c0d1d8a07405d901a6bc9e757afcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a13f74d685cc4e28b902aa70479a6ab1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17bb82c1a0dd4c7c947ff0ca5f6bd8a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/72.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7970bceb47944668829c54e384708c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cd9a61f00e74c91a46f340fa3ae0799",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)fetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91833525fe4843219b6bac4d37385bc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0cd754be538441a96d274f7d47294ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)of-00002.safetensors:   0%|          | 0.00/9.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63cd3068ef3449e98be53c9b6d8539bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)of-00002.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "054d70c3455244d68109cd78bec3a627",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcab350410474ae4aaa90878d7a722f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_id = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id,cache_dir=tokenizer_cache_dir)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id,cache_dir=model_cache_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e936b3b3-6b86-4465-861f-e872738c4f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saiving model to...  /nvmefs1/test_user/cache/model/mistral_7b_model_tokenizer\n",
      "Saiving model to...  /nvmefs1/test_user/cache/model/mistral_7b_model_tokenizer\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/nvmefs1/test_user/cache/model/mistral_7b_model_tokenizer/tokenizer_config.json',\n",
       " '/nvmefs1/test_user/cache/model/mistral_7b_model_tokenizer/special_tokens_map.json',\n",
       " '/nvmefs1/test_user/cache/model/mistral_7b_model_tokenizer/tokenizer.model',\n",
       " '/nvmefs1/test_user/cache/model/mistral_7b_model_tokenizer/added_tokens.json',\n",
       " '/nvmefs1/test_user/cache/model/mistral_7b_model_tokenizer/tokenizer.json')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Saiving model to... \", os.path.join(CACHE_DIR,'model/mistral_7b_model_tokenizer'))\n",
    "model.save_pretrained(os.path.join(CACHE_DIR,'model/mistral_7b_model_tokenizer'))\n",
    "print(\"Saiving model to... \", os.path.join(CACHE_DIR,'model/mistral_7b_model_tokenizer'))\n",
    "tokenizer.save_pretrained(os.path.join(CACHE_DIR,'model/mistral_7b_model_tokenizer'))\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5532438-d09e-43cf-a717-9da2d41a0c73",
   "metadata": {},
   "source": [
    "# Check if Model successfully downloaded by loading the model from our local directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0998282-503a-4a1f-96df-414a3b4798e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer from...  /nvmefs1/test_user/cache/model/mistral_7b_model_tokenizer\n",
      "Loading model from...  /nvmefs1/test_user/cache/model/mistral_7b_model_tokenizer\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47ad0f69e0bb4ea7aa7d9b817d90f73a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Some parameters are on the meta device device because they were offloaded to the cpu.\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading tokenizer from... \", os.path.join(CACHE_DIR,'model/mistral_7b_model_tokenizer'))\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained( os.path.join(CACHE_DIR,'model/mistral_7b_model_tokenizer'),cache_dir=tokenizer_cache_dir)\n",
    "print(\"Loading model from... \", os.path.join(CACHE_DIR,'model/mistral_7b_model_tokenizer'))\n",
    "model = AutoModelForCausalLM.from_pretrained(os.path.join(CACHE_DIR,'model/mistral_7b_model_tokenizer'),\n",
    "                                             cache_dir=model_cache_dir,\n",
    "                                            torch_dtype=torch.bfloat16,\n",
    "                                            device_map = \"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84bc4ae-0a54-45b3-8035-18a67f253985",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
